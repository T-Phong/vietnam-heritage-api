import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from datasets import load_dataset, load_from_disk
from typing import List, Dict, Any

from helper import format_metadata_list_to_context

# ==============================================================================
# Há»† THá»NG RAG 1: Sá»¬ Dá»¤NG HUGGING FACE DATASET
# ==============================================================================
class HuggingFaceRAGService:
    _instance = None
    
    # Singleton Pattern: Äáº£m báº£o chá»‰ cÃ³ má»™t instance cá»§a lá»›p nÃ y Ä‘Æ°á»£c táº¡o ra
    def __new__(cls):
        if cls._instance is None:
            print("Khá»Ÿi táº¡o HuggingFaceRAGService...")
            cls._instance = super(HuggingFaceRAGService, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        
        # Cáº¥u hÃ¬nh
        self.MODEL_NAME = "all-MiniLM-L6-v2"
        self.DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
        self.FAISS_PATH = os.path.join(self.DATA_DIR, "heritage.faiss")
        self.METADATA_PATH = os.path.join(self.DATA_DIR, "metadata.json")
        self.IDS_PATH = os.path.join(self.DATA_DIR, "ids.json")
        
        # Táº£i model vÃ  dá»¯ liá»‡u
        self._load_model()
        self._load_data()
        self._initialized = True
        print("âœ… HuggingFaceRAGService Ä‘Ã£ sáºµn sÃ ng.")

    def _load_model(self):
        print(f"ðŸ¤– [HF RAG] Äang táº£i model: {self.MODEL_NAME}...")
        self.model = SentenceTransformer(self.MODEL_NAME)

    def _load_data(self):
        self.index, self.metadata, self.ids = self._load_cache()
        if self.index and self.metadata and self.ids:
            print(f"ðŸ’¾ [HF RAG] Sá»­ dá»¥ng cache FAISS index vÃ  metadata (items: {len(self.ids)})")
        else:
            print("ðŸ’¾ [HF RAG] Cache khÃ´ng tá»“n táº¡i. Táº£i dataset vÃ  xÃ¢y dá»±ng FAISS index...")
            dataset = load_dataset("synguyen1106/vietnam_heritage_embeddings_v4", split="train")
            vectors = np.array(dataset['embedding']).astype("float32")
            self.metadata = [{k: v for k, v in dataset[i].items() if k not in ['embedding', 'id', 'slug']} for i in range(len(dataset))]
            self.ids = [dataset[i]['id'] for i in range(len(dataset))]
            print(f"ðŸ’¾ [HF RAG] ÄÃ£ táº£i {len(self.ids)} má»¥c tá»« dataset.")
            
            d = vectors.shape[1]
            self.index = faiss.IndexFlatL2(d)
            self.index.add(vectors)
            print("ðŸ”¨ [HF RAG] Sá»‘ lÆ°á»£ng vector trong FAISS index:", self.index.ntotal)
            
            self._save_cache(self.index, self.metadata, self.ids)
            print(f"ðŸ’¾ [HF RAG] ÄÃ£ lÆ°u cache táº¡i: {self.FAISS_PATH}")

    def _save_cache(self, faiss_index, metadata_list, ids_list):
        os.makedirs(self.DATA_DIR, exist_ok=True)
        faiss.write_index(faiss_index, self.FAISS_PATH)
        with open(self.METADATA_PATH, "w", encoding="utf-8") as f:
            json.dump(metadata_list, f, ensure_ascii=False)
        with open(self.IDS_PATH, "w", encoding="utf-8") as f:
            json.dump(ids_list, f, ensure_ascii=False)

    def _load_cache(self):
        if not (os.path.exists(self.FAISS_PATH) and os.path.exists(self.METADATA_PATH) and os.path.exists(self.IDS_PATH)):
            return None, None, None
        idx = faiss.read_index(self.FAISS_PATH)
        with open(self.METADATA_PATH, "r", encoding="utf-8") as f:
            meta = json.load(f)
        with open(self.IDS_PATH, "r", encoding="utf-8") as f:
            ids_local = json.load(f)
        return idx, meta, ids_local

    def search(self, query: str, k: int = 2) -> List[Dict[str, Any]]:
        query_vec = self.model.encode([query], convert_to_numpy=True).astype("float32")
        _, indices = self.index.search(query_vec, k)
        results = [{"metadata": self.metadata[int(idx)]} for idx in indices[0]]
        return results

# ==============================================================================
# Há»† THá»NG RAG 2: Sá»¬ Dá»¤NG LOCAL DISK DATASET
# ==============================================================================
class LocalDiskRAGService:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            print("\nKhá»Ÿi táº¡o LocalDiskRAGService...")
            cls._instance = super(LocalDiskRAGService, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        
        # Cáº¥u hÃ¬nh
        self.MODEL_NAME = 'keepitreal/vietnamese-sbert'
        self.DB_PATH = os.path.join(os.path.dirname(__file__), "..", "data", "vietnam_heritage_db_sbert_v1")
        self.MIN_CONTENT_LENGTH = 200
        self.CANDIDATE_MULTIPLIER = 5
        
        # Táº£i model vÃ  dá»¯ liá»‡u
        self._load_model()
        self._load_data()
        self._initialized = True
        print("âœ… LocalDiskRAGService Ä‘Ã£ sáºµn sÃ ng.")

    def _load_model(self):
        print(f"ðŸ¤– [Local RAG] Äang táº£i model AI: {self.MODEL_NAME}...")
        self.model = SentenceTransformer(self.MODEL_NAME)

    def _load_data(self):
        print(f"ðŸ’¾ [Local RAG] Äang táº£i dá»¯ liá»‡u tá»«: {self.DB_PATH}...")
        if not os.path.exists(self.DB_PATH):
            print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c táº¡i {self.DB_PATH}")
            self.dataset = None
            return
        
        self.dataset = load_from_disk(self.DB_PATH)
        print(f"ðŸ’¾ [Local RAG] Load xong! Tá»•ng sá»‘ dá»¯ liá»‡u: {len(self.dataset)} dÃ²ng.")
        
        print("ðŸ”¨ [Local RAG] Äang kÃ­ch hoáº¡t bá»™ tÃ¬m kiáº¿m (Re-indexing)...")
        self.dataset.add_faiss_index(column="embeddings")
        print("ðŸ”¨ [Local RAG] ÄÃ£ kÃ­ch hoáº¡t xong FAISS Index!")

    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        if not self.dataset:
            return []
            
        # print(f"\nðŸ”Ž [Local RAG] Äang tÃ¬m: '{query}'")
        # print("-" * 50)

        query_vector = self.model.encode(query)
        candidate_k = top_k * self.CANDIDATE_MULTIPLIER
        scores, samples = self.dataset.get_nearest_examples("embeddings", query_vector, k=candidate_k)

        results = []
        for i in range(len(samples['original_content'])):
            if len(results) >= top_k:
                break
            
            content = samples['original_content'][i]
            if len(content) < self.MIN_CONTENT_LENGTH:
                continue

            score = scores[i]
            metadata = samples['metadata'][i]
            metadata['content'] = content
            
            results.append({
                "metadata": metadata,
                "score": score
            })
            
            # In ra console Ä‘á»ƒ debug nhÆ° hÃ m gá»‘c
            # print(f"Top {len(results)} (Äá»™ sai lá»‡ch: {score:.2f}):")
            # print(f"Ná»™i dung: {content[:200]}...")
            # print("-" * 50)

        if not results:
            print(f"KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o cÃ³ ná»™i dung dÃ i hÆ¡n {self.MIN_CONTENT_LENGTH} kÃ½ tá»±.")
        
        return results

# ==============================================================================
# KHá»žI Táº O SERVICE VÃ€ CUNG Cáº¤P CÃC HÃ€M Gá»C
# ==============================================================================
hf_rag_service = HuggingFaceRAGService()
local_rag_service = LocalDiskRAGService()

def retrieve_context(query: str, k: int = 2) -> str:
    """
    TÃ¬m kiáº¿m ngá»¯ cáº£nh sá»­ dá»¥ng há»‡ thá»‘ng RAG tá»« Hugging Face.
    (Giá»¯ nguyÃªn hÃ m gá»‘c Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch)
    """
    print("\n>>> Sá»­ dá»¥ng há»‡ thá»‘ng RAG 1 (HuggingFace)...")
    results = hf_rag_service.search(query, k)
    return format_metadata_list_to_context(results)

def search_heritage(query: str, top_k: int = 3) -> str:
    """
    TÃ¬m kiáº¿m di sáº£n sá»­ dá»¥ng há»‡ thá»‘ng RAG tá»« á»• Ä‘Ä©a cá»¥c bá»™.
    (Giá»¯ nguyÃªn hÃ m gá»‘c Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch)
    """
    print("\n>>> Sá»­ dá»¥ng há»‡ thá»‘ng RAG 2 (Local Disk)...")
    results = local_rag_service.search(query, top_k)
    return format_metadata_list_to_context(results)